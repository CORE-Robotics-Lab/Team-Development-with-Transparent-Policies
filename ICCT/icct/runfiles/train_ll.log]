Using cuda device
Wrapping the env in a DummyVecEnv.
OrderedDict([('comparators', tensor([[ 1.7641],
        [ 0.4002],
        [ 0.9787],
        [ 2.2409],
        [ 1.8676],
        [-0.9773],
        [ 0.9501]], device='cuda:0')), ('layers', tensor([[0.9637, 0.3834, 0.7917, 0.5289, 0.5680, 0.9256, 0.0710, 0.0871],
        [0.0202, 0.8326, 0.7782, 0.8700, 0.9786, 0.7992, 0.4615, 0.7805],
        [0.1183, 0.6399, 0.1434, 0.9447, 0.5218, 0.4147, 0.2646, 0.7742],
        [0.4562, 0.5684, 0.0188, 0.6176, 0.6121, 0.6169, 0.9437, 0.6818],
        [0.3595, 0.4370, 0.6976, 0.0602, 0.6668, 0.6706, 0.2104, 0.1289],
        [0.3154, 0.3637, 0.5702, 0.4386, 0.9884, 0.1020, 0.2089, 0.1613],
        [0.6531, 0.2533, 0.4663, 0.2444, 0.1590, 0.1104, 0.6563, 0.1382]],
       device='cuda:0')), ('alpha', tensor([[1.],
        [1.],
        [1.],
        [1.],
        [1.],
        [1.],
        [1.]], device='cuda:0')), ('left_path_sigs', tensor([[1., 1., 1., 1., 0., 0., 0., 0.],
        [1., 1., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 1., 1., 0., 0.],
        [1., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 1., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 1., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 1., 0.]], device='cuda:0')), ('right_path_sigs', tensor([[0., 0., 0., 0., 1., 1., 1., 1.],
        [0., 0., 1., 1., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 1., 1.],
        [0., 1., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 1., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 1., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 1.]], device='cuda:0')), ('action_stds', tensor([[-0.1564,  0.0258],
        [-0.7360,  0.6818],
        [ 0.6907,  0.4597],
        [-0.1317,  0.4961],
        [-0.4198,  0.6345],
        [-0.5913, -0.6581],
        [-0.1406,  0.7127],
        [-0.4503, -0.4741]], device='cuda:0')), ('sub_scalars', tensor([[[ 0.0286, -0.0873,  0.1461, -0.1162,  0.2182,  0.1372,  0.0205,
          -0.1487],
         [ 0.1282,  0.1395, -0.1602, -0.0575,  0.0807,  0.0661, -0.1089,
          -0.0213]],

        [[-0.0492,  0.2833, -0.1341,  0.2606,  0.0629, -0.0828,  0.0314,
          -0.0214],
         [-0.0439, -0.1227,  0.1595, -0.0841,  0.1125,  0.0852,  0.2929,
           0.0463]],

        [[-0.0393, -0.0888,  0.4786, -0.0106, -0.0623, -0.0178,  0.3097,
           0.2955],
         [-0.0847, -0.0206,  0.0097, -0.0461,  0.3597,  0.0169, -0.0016,
           0.0656]],

        [[-0.2467, -0.1430,  0.3191,  0.0389, -0.2983,  0.4039,  0.1640,
          -0.2961],
         [-0.1387, -0.0326,  0.1868, -0.0278, -0.1208,  0.1128,  0.0801,
           0.0591]],

        [[ 0.3270, -0.2067, -0.0351, -0.0351,  0.0299, -0.0888, -0.2213,
           0.0947],
         [-0.0046,  0.1350, -0.2137, -0.0917,  0.2002, -0.2742,  0.0336,
          -0.0445]],

        [[-0.1456,  0.0496,  0.0212,  0.1154,  0.1731,  0.0823, -0.0627,
           0.0767],
         [ 0.0462,  0.1543, -0.0440, -0.0882,  0.0831, -0.0039,  0.3108,
          -0.1127]],

        [[-0.1665,  0.0600, -0.0987, -0.0313,  0.0793, -0.0465,  0.0745,
          -0.1172],
         [-0.0637,  0.0351,  0.1491, -0.0441, -0.1376, -0.1360, -0.2396,
          -0.0759]],

        [[-0.1439, -0.0508,  0.1952, -0.2380,  0.0999, -0.2257,  0.0287,
           0.0861],
         [ 0.1169, -0.1032,  0.0684,  0.2817,  0.0367,  0.0216,  0.2008,
          -0.0639]]], device='cuda:0')), ('sub_weights', tensor([[[ 0.4023, -0.1133, -0.0780,  0.0200,  0.0160, -0.0638,  0.1427,
           0.1281],
         [-0.1088,  0.0217,  0.1641,  0.0146, -0.0593, -0.0144,  0.3263,
          -0.2872]],

        [[-0.0430,  0.0444, -0.1644,  0.1228,  0.1394,  0.0070, -0.2351,
           0.1792],
         [ 0.2098, -0.1995,  0.1502, -0.1037,  0.1438, -0.0995, -0.1041,
           0.3291]],

        [[ 0.2237, -0.0489, -0.0325,  0.3251, -0.0078, -0.1006, -0.0847,
          -0.0207],
         [-0.0466,  0.1941,  0.1668,  0.0565,  0.2590, -0.0365,  0.1246,
          -0.0128]],

        [[-0.0620,  0.2004,  0.1647, -0.0782, -0.1840,  0.2489,  0.1125,
           0.0965],
         [ 0.2032, -0.1033,  0.1766, -0.1592,  0.2042,  0.2534,  0.0211,
           0.1692]],

        [[-0.1765, -0.1327, -0.5800,  0.1295,  0.0198, -0.1216,  0.0245,
          -0.1389],
         [-0.0749,  0.1532, -0.3160,  0.0163,  0.1357,  0.1206, -0.1990,
          -0.1294]],

        [[ 0.2847, -0.1251,  0.0316,  0.2678, -0.1860,  0.1054,  0.1386,
          -0.2024],
         [ 0.1830, -0.3115,  0.3274, -0.1775, -0.0165, -0.1615, -0.0522,
          -0.1363]],

        [[ 0.0384,  0.2728, -0.2766, -0.2876,  0.1000,  0.1117,  0.1168,
           0.0599],
         [ 0.1412, -0.2475, -0.0020, -0.2925,  0.0790, -0.0221,  0.0402,
           0.0289]],

        [[-0.0606,  0.1408, -0.0220,  0.2806,  0.1155, -0.0351, -0.0535,
          -0.1349],
         [-0.0649, -0.1057,  0.2607,  0.2432,  0.2947, -0.0284,  0.2183,
          -0.0479]]], device='cuda:0')), ('sub_biases', tensor([[[ 0.0556, -0.2241, -0.1320,  0.0489, -0.1289,  0.1149, -0.0702,
           0.0651],
         [-0.0208, -0.0393, -0.1858,  0.1004, -0.0603,  0.1266, -0.1272,
           0.0834]],

        [[ 0.1422,  0.1950, -0.0939, -0.1744,  0.1717,  0.0502,  0.1495,
          -0.0371],
         [-0.4034,  0.0993, -0.3629,  0.1515,  0.1743,  0.0824, -0.0749,
           0.2466]],

        [[ 0.0767,  0.0767,  0.3354, -0.1987,  0.0217, -0.3572, -0.0905,
          -0.0414],
         [-0.0259,  0.1278, -0.1298, -0.2134, -0.2217,  0.0184, -0.2322,
          -0.2087]],

        [[ 0.1594,  0.1986,  0.1198,  0.1357,  0.2960, -0.6102,  0.0561,
           0.0165],
         [-0.0869, -0.2473, -0.0531,  0.5253,  0.0274,  0.1414, -0.1448,
           0.1884]],

        [[ 0.2997,  0.1353, -0.0554, -0.2236,  0.0285,  0.0140, -0.1943,
          -0.0479],
         [ 0.0323, -0.1324, -0.0521,  0.0349,  0.1512,  0.2119,  0.0706,
           0.3678]],

        [[ 0.1557,  0.2388,  0.1942,  0.0928,  0.0894,  0.1537,  0.0350,
           0.1280],
         [ 0.0526,  0.1491, -0.0987,  0.0773, -0.0280,  0.1082,  0.1759,
           0.1882]],

        [[-0.2174,  0.1895, -0.0460, -0.1126,  0.0356, -0.2475,  0.2368,
           0.1735],
         [-0.1251,  0.2295,  0.0473,  0.0802,  0.0586,  0.2677,  0.0888,
           0.1945]],

        [[ 0.2500,  0.0517, -0.0077,  0.0873,  0.3058,  0.3196,  0.1474,
           0.2321],
         [-0.0801, -0.1499,  0.0530,  0.1036, -0.0087,  0.1838,  0.1254,
          -0.0676]]], device='cuda:0'))])
Logging to ../../log/ll/SAC_41
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 93.5     |
|    ep_rew_mean     | -194     |
| time/              |          |
|    episodes        | 4        |
|    fps             | 73       |
|    time_elapsed    | 5        |
|    total timesteps | 374      |
| train/             |          |
|    actor_loss      | 1.23     |
|    critic_loss     | 27.5     |
|    ent_coef        | 0.872    |
|    ent_coef_loss   | -0.431   |
|    n_updates       | 273      |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 98.9     |
|    ep_rew_mean     | -219     |
| time/              |          |
|    episodes        | 8        |
|    fps             | 72       |
|    time_elapsed    | 10       |
|    total timesteps | 791      |
| train/             |          |
|    actor_loss      | 2.85     |
|    critic_loss     | 16.7     |
|    ent_coef        | 0.707    |
|    ent_coef_loss   | -1.14    |
|    n_updates       | 690      |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 101      |
|    ep_rew_mean     | -210     |
| time/              |          |
|    episodes        | 12       |
|    fps             | 71       |
|    time_elapsed    | 16       |
|    total timesteps | 1210     |
| train/             |          |
|    actor_loss      | 9.79     |
|    critic_loss     | 9.83     |
|    ent_coef        | 0.574    |
|    ent_coef_loss   | -1.76    |
|    n_updates       | 1109     |
---------------------------------
Eval num_timesteps=1500, episode_reward=-137.31 +/- 35.25
Episode length: 84.80 +/- 24.90
New best mean reward!
---------------------------------
| eval/              |          |
|    mean_ep_length  | 84.8     |
|    mean_reward     | -137     |
| rollout/           |          |
|    ep_len_mean     | 98.9     |
|    ep_rew_mean     | -194     |
| time/              |          |
|    episodes        | 16       |
|    fps             | 64       |
|    time_elapsed    | 24       |
|    total timesteps | 1582     |
| train/             |          |
|    actor_loss      | 12.4     |
|    critic_loss     | 39.4     |
|    ent_coef        | 0.48     |
|    ent_coef_loss   | -2.22    |
|    n_updates       | 1481     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 101      |
|    ep_rew_mean     | -203     |
| time/              |          |
|    episodes        | 20       |
|    fps             | 64       |
|    time_elapsed    | 31       |
|    total timesteps | 2023     |
| train/             |          |
|    actor_loss      | 20.1     |
|    critic_loss     | 10.4     |
|    ent_coef        | 0.39     |
|    ent_coef_loss   | -2.65    |
|    n_updates       | 1922     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 98.9     |
|    ep_rew_mean     | -187     |
| time/              |          |
|    episodes        | 24       |
|    fps             | 64       |
|    time_elapsed    | 36       |
|    total timesteps | 2373     |
| train/             |          |
|    actor_loss      | 23       |
|    critic_loss     | 40.8     |
|    ent_coef        | 0.331    |
|    ent_coef_loss   | -3.21    |
|    n_updates       | 2272     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 104      |
|    ep_rew_mean     | -173     |
| time/              |          |
|    episodes        | 28       |
|    fps             | 64       |
|    time_elapsed    | 44       |
|    total timesteps | 2899     |
| train/             |          |
|    actor_loss      | 22.9     |
|    critic_loss     | 9.86     |
|    ent_coef        | 0.261    |
|    ent_coef_loss   | -3.28    |
|    n_updates       | 2798     |
---------------------------------
Eval num_timesteps=3000, episode_reward=-286.50 +/- 254.39
Episode length: 242.40 +/- 94.18
---------------------------------
| eval/              |          |
|    mean_ep_length  | 242      |
|    mean_reward     | -287     |
| rollout/           |          |
|    ep_len_mean     | 113      |
|    ep_rew_mean     | -172     |
| time/              |          |
|    episodes        | 32       |
|    fps             | 61       |
|    time_elapsed    | 58       |
|    total timesteps | 3601     |
| train/             |          |
|    actor_loss      | 30.3     |
|    critic_loss     | 11.1     |
|    ent_coef        | 0.192    |
|    ent_coef_loss   | -3.66    |
|    n_updates       | 3500     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 118      |
|    ep_rew_mean     | -166     |
| time/              |          |
|    episodes        | 36       |
|    fps             | 61       |
|    time_elapsed    | 69       |
|    total timesteps | 4244     |
| train/             |          |
|    actor_loss      | 33.7     |
|    critic_loss     | 14.1     |
|    ent_coef        | 0.148    |
|    ent_coef_loss   | -3.52    |
|    n_updates       | 4143     |
---------------------------------
Eval num_timesteps=4500, episode_reward=-91.80 +/- 89.03
Episode length: 177.80 +/- 139.94
New best mean reward!
