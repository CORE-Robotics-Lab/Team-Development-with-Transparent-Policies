Average reward for initial policy: 400.1 +/- 36.1
Average reward after fine-tuning human policy: 170.1 +/- 117.19
Average reward after fine-tuning intent model: 175.3 +/- 109.83
Average reward after fine-tuning robot policy: 157.7 +/- 94.74

Hyperparameters:
[main]
layout: forced_coordination
prior_iteration_data: data/iteration_0.tar
n_episode_samples: 10
n_random_seeds: 1

hpo: true
hpo_lr: 0.0005
hpo_n_epochs: 50

ipo: true
ipo_lr: 0.005
ipo_n_epochs: 50

rpo: true
rpo_ga: false
rpo_rl: true
rpo_random_initial_idct: false

rpo_ga_data_file: data/11_trajs_tar
rpo_ga_depth: 3
rpo_ga_n_gens: 100
rpo_ga_n_pop: 30
rpo_ga_n_parents_mating: 15
rpo_ga_crossover_prob: 0.5
rpo_ga_crossover_type: two_points
rpo_ga_mutation_prob: 0.2
rpo_ga_mutation_type: random

rpo_rl_lr: 0.0003
rpo_rl_n_steps: 5000
